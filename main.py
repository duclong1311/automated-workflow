import os
import json
import logging
import re
import html
import asyncio
import requests
from io import BytesIO
from datetime import datetime
from fastapi import FastAPI, Request, BackgroundTasks
from jira import JIRA
from google import genai
from dotenv import load_dotenv
from common import GEMINI_PARSE_PROMPT, Messages, Config
from fastapi import Response
import sys
# Ensure project root is on sys.path so local packages import correctly when running main.py
sys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))
from handlers.bitbucket_handler import process_bitbucket_event
from services.jira_service import JiraService
from models.task_info import TaskInfo
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()
app = FastAPI()

# L·∫•y bi·∫øn m√¥i tr∆∞·ªùng
JIRA_SERVER = os.getenv("JIRA_SERVER", "").strip()
JIRA_API_TOKEN = os.getenv("JIRA_API_TOKEN", "").strip()
JIRA_PROJECT_KEY = os.getenv("JIRA_PROJECT_KEY", "").strip()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "").strip()

# Kh·ªüi t·∫°o Jira Service (thay v√¨ global jira)
jira_service = JiraService()

# Gi·ªØ bi·∫øn jira global ƒë·ªÉ backward compatibility (s·∫Ω deprecated)
jira = jira_service.jira if jira_service.jira else None

client_ai = None
try:
    client_ai = genai.Client(api_key=GEMINI_API_KEY)
    logger.info("‚úÖ K·∫øt n·ªëi Gemini AI th√†nh c√¥ng.")
except Exception as e:
    logger.error(f"‚ùå L·ªói k·∫øt n·ªëi Gemini AI: {e}")

def clean_teams_message(raw_text):
    """L√†m s·∫°ch HTML message t·ª´ Teams v√† parse mention tags"""
    # B∆∞·ªõc 1: T√¨m v√† gh√©p c√°c mention tags li√™n ti·∫øp th√†nh t√™n ƒë·∫ßy ƒë·ªß
    at_pattern = r'<at[^>]*>([^<]+)</at>'
    mentions = []
    for match in re.finditer(at_pattern, raw_text):
        mention_text = match.group(1).strip()
        mention_text = html.unescape(mention_text)
        if len(mention_text) <= 50 and not re.search(r'[\[\]‚Äª]', mention_text):
            mentions.append(mention_text)
    
    # T√¨m c√°c mention tags li√™n ti·∫øp c√≥ v·∫ª l√† t√™n (tr∆∞·ªõc "v√†" ho·∫∑c "epic link")
    # T√¨m v·ªã tr√≠ c·ªßa "g·∫Øn cho" ho·∫∑c "g√°n cho"
    assignee_from_mentions = None
    g·∫Øn_cho_pattern = r'(?:g·∫Øn|g√°n)\s+(?:cho|task\s+n√†y\s+cho)'
    g·∫Øn_match = re.search(g·∫Øn_cho_pattern, raw_text, re.IGNORECASE)
    
    if g·∫Øn_match:
        # T√¨m c√°c mention tags sau "g·∫Øn cho" v√† tr∆∞·ªõc "v√†" ho·∫∑c "epic link"
        start_pos = g·∫Øn_match.end()
        end_pattern = r'(?:\s+v√†|\s+and|epic\s+link|$)'
        end_match = re.search(end_pattern, raw_text[start_pos:], re.IGNORECASE)
        end_pos = start_pos + (end_match.start() if end_match else len(raw_text))
        
        # L·∫•y ph·∫ßn text gi·ªØa "g·∫Øn cho" v√† "v√†/epic link"
        text_between = raw_text[start_pos:end_pos]
        
        # T√¨m t·∫•t c·∫£ mention tags trong ph·∫ßn n√†y
        name_parts = []
        for match in re.finditer(at_pattern, text_between):
            mention_text = match.group(1).strip()
            mention_text = html.unescape(mention_text)
            # Lo·∫°i b·ªè ph·∫ßn trong ngo·∫∑c ƒë∆°n
            if not mention_text.startswith('(') and not mention_text.endswith(')'):
                if len(mention_text) <= 20 and not re.search(r'[\(\)\[\]‚Äª]', mention_text):
                    name_parts.append(mention_text)
        
        if name_parts:
            # Gh√©p c√°c ph·∫ßn th√†nh t√™n ƒë·∫ßy ƒë·ªß
            assignee_from_mentions = ' '.join(name_parts).strip()
    
    # B∆∞·ªõc 2: T√¨m pattern "g√°n cho X" trong text (sau khi thay th·∫ø mention tags)
    # Thay th·∫ø t·∫•t c·∫£ mention tags b·∫±ng text ƒë·ªÉ d·ªÖ t√¨m pattern
    text_with_mentions_replaced = raw_text
    for match in re.finditer(at_pattern, raw_text):
        mention_text = match.group(1).strip()
        mention_text = html.unescape(mention_text)
        # Thay th·∫ø b·∫±ng text, gi·ªØ nguy√™n kho·∫£ng tr·∫Øng
        text_with_mentions_replaced = text_with_mentions_replaced.replace(match.group(0), mention_text)
    
    # Thay th·∫ø &nbsp; b·∫±ng space
    text_with_mentions_replaced = text_with_mentions_replaced.replace('&nbsp;', ' ')
    text_with_mentions_replaced = html.unescape(text_with_mentions_replaced)
    
    assignee_from_text = None
    assignee_patterns = [
        r't·∫°o\s+task\s+g·∫Øn\s+cho\s+([^\n,<]+?)(?:\s+v√†|\s+and|epic|$)',  # "t·∫°o task g·∫Øn cho X"
        r'g·∫Øn\s+cho\s+([^\n,<]+?)(?:\s+v√†|\s+and|epic|$)',  # "g·∫Øn cho X"
        r'g√°n\s+(?:task\s+n√†y\s+)?cho\s+([^\n,<]+?)(?:\s+v√†|\s+and|epic|$)',  # "g√°n cho X"
    ]
    
    for pattern in assignee_patterns:
        match = re.search(pattern, text_with_mentions_replaced, re.IGNORECASE)
        if match:
            assignee_from_text = match.group(1).strip()
            # Lo·∫°i b·ªè HTML tags n·∫øu c√≥
            assignee_from_text = re.sub(r'<[^>]+>', '', assignee_from_text)
            assignee_from_text = html.unescape(assignee_from_text)
            # Lo·∫°i b·ªè ph·∫ßn trong ngo·∫∑c ƒë∆°n
            assignee_from_text = re.sub(r'\s*\([^)]+\)', '', assignee_from_text).strip()
            if assignee_from_text and len(assignee_from_text) > 2:
                break
    
    # ∆Øu ti√™n d√πng assignee t·ª´ mention tags n·∫øu c√≥ (th∆∞·ªùng ch√≠nh x√°c h∆°n)
    assignee_from_text = assignee_from_mentions if assignee_from_mentions else assignee_from_text
    
    # Parse mention tags (ch·ªâ l·∫•y mention th·ª±c s·ª± - t√™n ng∆∞·ªùi)
    # Teams mention format: <at>Name</at> ho·∫∑c <at id="...">Name</at>
    mentions = []
    
    # T√¨m t·∫•t c·∫£ mention tags: <at>Name</at> ho·∫∑c <at id="...">Name</at>
    # Ch·ªâ l·∫•y nh·ªØng mention c√≥ v·∫ª l√† t√™n ng∆∞·ªùi (kh√¥ng qu√° d√†i, kh√¥ng c√≥ k√Ω t·ª± ƒë·∫∑c bi·ªát nhi·ªÅu)
    at_pattern = r'<at[^>]*>([^<]+)</at>'
    for match in re.finditer(at_pattern, raw_text):
        mention_text = match.group(1).strip()
        # Clean HTML entities
        mention_text = html.unescape(mention_text)
        # Ch·ªâ l·∫•y mention n·∫øu c√≥ v·∫ª l√† t√™n ng∆∞·ªùi (kh√¥ng qu√° 50 k√Ω t·ª±, kh√¥ng ch·ª©a nhi·ªÅu k√Ω t·ª± ƒë·∫∑c bi·ªát)
        if len(mention_text) <= 50 and not re.search(r'[\[\]‚Äª]', mention_text):
            mentions.append(mention_text)
            # Thay th·∫ø b·∫±ng text ƒë∆°n gi·∫£n ƒë·ªÉ d·ªÖ parse
            raw_text = raw_text.replace(match.group(0), mention_text)
    
    # Clean HTML
    clean = re.sub(r'</p>|</div>|<br\s*/?>|</li>', '\n', raw_text)
    clean = re.sub(r'<[^>]+>', '', clean)
    clean = html.unescape(clean)
    clean = '\n'.join(line.strip() for line in clean.split('\n'))
    clean = re.sub(r'\n\n+', '\n\n', clean).strip()
    
    # N·∫øu c√≥ mentions h·ª£p l·ªá V√Ä ch∆∞a t√¨m th·∫•y assignee t·ª´ text g·ªëc
    if mentions and not assignee_from_text:
        # L·ªçc mentions - ch·ªâ l·∫•y nh·ªØng c√°i c√≥ v·∫ª l√† t√™n ng∆∞·ªùi (kh√¥ng ph·∫£i bot, kh√¥ng ph·∫£i text d√†i)
        valid_mentions = [m.strip() for m in mentions if m.lower() != 'jirabot' and len(m.strip()) <= 30 and not m.strip().startswith('[') and not re.search(r'[\[\]‚Äª&nbsp;]', m)]
        
        # Gh√©p c√°c t·ª´ li√™n ti·∫øp th√†nh t√™n ƒë·∫ßy ƒë·ªß (v√≠ d·ª•: "Tr·∫ßn", "ƒê·ª©c", "Long" -> "Tr·∫ßn ƒê·ª©c Long")
        if valid_mentions:
            # T√¨m c√°c t·ª´ li√™n ti·∫øp c√≥ v·∫ª l√† t√™n (kh√¥ng c√≥ k√Ω t·ª± ƒë·∫∑c bi·ªát, kh√¥ng qu√° ng·∫Øn)
            full_names = []
            current_name_parts = []
            
            for mention in valid_mentions:
                # Clean mention
                mention_clean = re.sub(r'[&nbsp;\xa0]', ' ', mention).strip()
                # N·∫øu l√† t·ª´ ƒë∆°n (kh√¥ng c√≥ space, kh√¥ng c√≥ k√Ω t·ª± ƒë·∫∑c bi·ªát, ƒë·ªô d√†i h·ª£p l√Ω)
                if len(mention_clean) > 0 and len(mention_clean) <= 20 and not re.search(r'[\(\)\[\]‚Äª]', mention_clean):
                    if not mention_clean.startswith('(') and not mention_clean.endswith(')'):
                        current_name_parts.append(mention_clean)
                    else:
                        # N·∫øu c√≥ ph·∫ßn trong ngo·∫∑c, k·∫øt th√∫c t√™n hi·ªán t·∫°i
                        if current_name_parts:
                            full_names.append(' '.join(current_name_parts))
                            current_name_parts = []
                else:
                    # N·∫øu kh√¥ng ph·∫£i t·ª´ ƒë∆°n, k·∫øt th√∫c t√™n hi·ªán t·∫°i
                    if current_name_parts:
                        full_names.append(' '.join(current_name_parts))
                        current_name_parts = []
                    # N·∫øu l√† t√™n ƒë·∫ßy ƒë·ªß (c√≥ space ho·∫∑c d√†i), th√™m tr·ª±c ti·∫øp
                    if len(mention_clean) > 3 and (' ' in mention_clean or len(mention_clean) > 10):
                        full_names.append(mention_clean)
            
            # Th√™m t√™n cu·ªëi c√πng n·∫øu c√≤n
            if current_name_parts:
                full_names.append(' '.join(current_name_parts))
            
            # L·ªçc l·∫°i - ch·ªâ l·∫•y t√™n c√≥ v·∫ª h·ª£p l·ªá (kh√¥ng qu√° ng·∫Øn, kh√¥ng c√≥ k√Ω t·ª± ƒë·∫∑c bi·ªát)
            final_mentions = [name for name in full_names if len(name) >= 3 and len(name) <= 50 and not re.search(r'[\[\]‚Äª]', name)]
            
            if final_mentions:
                # ∆Øu ti√™n d√πng assignee t·ª´ text g·ªëc n·∫øu c√≥ (ƒë√£ gh√©p t·ª´ mention tags)
                if assignee_from_text:
                    # T√¨m pattern "g√°n cho X" ho·∫∑c "g·∫Øn cho X" trong text ƒë·ªÉ thay th·∫ø
                    assignee_match = re.search(r'(?:g√°n|g·∫Øn)\s+(?:task\s+n√†y\s+)?cho\s+([^\n,]+?)(?:\s+v√†|\s+and|$)', clean, re.IGNORECASE)
                    if assignee_match:
                        # Thay th·∫ø b·∫±ng t√™n ƒë·∫ßy ƒë·ªß t·ª´ text g·ªëc
                        old_text = assignee_match.group(0)
                        new_text = f"g√°n cho {assignee_from_text}"
                        clean = clean.replace(old_text, new_text)
                    else:
                        # N·∫øu kh√¥ng t√¨m th·∫•y, th√™m v√†o
                        clean = f"{clean}\ng√°n cho {assignee_from_text}"
                else:
                    # T√¨m pattern "g√°n cho X" trong text ƒë·ªÉ l·∫•y t√™n ƒë·∫ßy ƒë·ªß
                    assignee_match = re.search(r'g√°n\s+(?:task\s+n√†y\s+)?cho\s+([^\n,]+?)(?:\s+v√†|\s+and|$)', clean, re.IGNORECASE)
                    if not assignee_match:
                        # N·∫øu text kh√¥ng c√≥ "g√°n cho" ho·∫∑c "assign to", th√™m mention v√†o
                        # Ch·ªâ th√™m n·∫øu t√™n ƒë·ªß d√†i (√≠t nh·∫•t 2 t·ª´)
                        best_mention = None
                        for mention in final_mentions:
                            if len(mention.split()) >= 2:  # √çt nh·∫•t 2 t·ª´
                                best_mention = mention
                                break
                        if not best_mention and final_mentions:
                            best_mention = final_mentions[0]
                        
                        if best_mention:
                            clean = f"{clean}\ng√°n cho {best_mention}"
    
    return clean

def ask_gemini_to_parse_task(text):
    """Ph√¢n t√≠ch task v·ªõi timeout 1s"""
    try:
        prompt = GEMINI_PARSE_PROMPT.format(text=text)
        
        response = client_ai.models.generate_content(
            model='gemini-2.5-flash',
            contents=prompt,
            config={
                'response_mime_type': 'application/json',
                'temperature': 0.1,  # Gi·∫£m creativity ƒë·ªÉ nhanh h∆°n
            }
        )
        
        # Parse JSON an to√†n
        response_text = response.text.strip()
        
        # X√≥a markdown code block n·∫øu c√≥
        if response_text.startswith('```'):
            response_text = re.sub(r'^```(?:json)?\s*', '', response_text)
            response_text = re.sub(r'\s*```$', '', response_text)
        
        # Parse JSON
        result = json.loads(response_text)
        
        # Validate required fields
        if not result.get('summary'):
            result['summary'] = text.split('\n')[0][:100]  
        if not result.get('issuetype'):
            result['issuetype'] = 'Task'
        if not result.get('description'):
            result['description'] = text
        if not result.get('priority'):
            result['priority'] = 'Medium'
        if 'epic_link' not in result:
            result['epic_link'] = None
        if 'assignee' not in result:
            result['assignee'] = None
        
        # Clean epic_link v√† assignee
        if result.get('epic_link'):
            epic_link_value = result['epic_link']
            if isinstance(epic_link_value, str):
                # Lo·∫°i b·ªè c√°c t·ª´ th·ª´a ·ªü cu·ªëi
                epic_link_value = re.sub(r'\s+(?:v√†|and|cho|to|for).*$', '', epic_link_value, flags=re.IGNORECASE).strip()
                result['epic_link'] = epic_link_value if epic_link_value else None
            elif not epic_link_value:
                result['epic_link'] = None
        else:
            result['epic_link'] = None
        
        if result.get('assignee'):
            assignee_value = result['assignee']
            if isinstance(assignee_value, str):
                # Lo·∫°i b·ªè ph·∫ßn trong ngo·∫∑c ƒë∆°n (nh∆∞ "(KHN.SBU3.DEV)")
                assignee_value_after_paren = re.sub(r'\s*\([^)]+\)', '', assignee_value).strip()
                # Lo·∫°i b·ªè c√°c t·ª´ th·ª´a ·ªü cu·ªëi
                assignee_value = re.sub(r'\s+(?:v√†|and|cho|to|for).*$', '', assignee_value_after_paren, flags=re.IGNORECASE).strip()
                result['assignee'] = assignee_value if assignee_value else None
            elif not assignee_value:
                result['assignee'] = None
        else:
            result['assignee'] = None
        
        # Clean description: lo·∫°i b·ªè ph·∫ßn instruction v·ªÅ assignee v√† epic link
        if result.get('description'):
            description = result['description']
            # Lo·∫°i b·ªè c√°c d√≤ng ch·ª©a instruction
            lines = description.split('\n')
            cleaned_lines = []
            for line in lines:
                # Lo·∫°i b·ªè d√≤ng ch·ª©a "g√°n", "assign", "epic link", "h√£y g√°n"
                if not re.search(r'(g√°n|assign|epic\s+link|h√£y\s+g√°n)', line, re.IGNORECASE):
                    cleaned_lines.append(line)
            result['description'] = '\n'.join(cleaned_lines).strip()
        
        # IMPORTANT: N·∫øu c√≥ epic_link th√¨ ph·∫£i l√† Task, kh√¥ng ph·∫£i Epic
        # (epic_link = li√™n k·∫øt v·ªõi epic c√≥ s·∫µn, kh√¥ng ph·∫£i t·∫°o Epic m·ªõi)
        if result.get('epic_link') and result.get('issuetype') == 'Epic':
            logger.warning(f"‚ö†Ô∏è C√≥ epic_link nh∆∞ng issuetype l√† Epic, ƒë·ªïi th√†nh Task")
            result['issuetype'] = 'Task'
            
        logger.info(f"‚úÖ Parsed task: {result.get('issuetype')} - {result.get('summary')[:50]}")
        if result.get('epic_link'):
            logger.info(f"   Epic link: {result.get('epic_link')}")
        if result.get('assignee'):
            logger.info(f"   Assignee: {result.get('assignee')}")
        return result
        
    except json.JSONDecodeError as e:
        logger.error(f"‚ùå JSON Parse Error: {e}")
        logger.error(f"   Response text: {response.text[:500]}")
        # Fallback: d√πng quick_parse ƒë·ªÉ gi·ªØ l·∫°i epic link v√† assignee
        logger.warning("‚ö†Ô∏è D√πng fallback parsing do JSON error")
        return quick_parse_fallback(text)
    except AttributeError as e:
        logger.error(f"‚ùå Response Error: {e}")
        logger.error(f"   Check if response object valid")
        # Fallback: d√πng quick_parse ƒë·ªÉ gi·ªØ l·∫°i epic link v√† assignee
        logger.warning("‚ö†Ô∏è D√πng fallback parsing do AttributeError")
        return quick_parse_fallback(text)
    except Exception as e:
        logger.error(f"‚ùå Gemini Error: {type(e).__name__}: {e}")
        import traceback
        logger.error(traceback.format_exc())
        # Fallback: d√πng quick_parse ƒë·ªÉ gi·ªØ l·∫°i epic link v√† assignee
        logger.warning("‚ö†Ô∏è D√πng fallback parsing do exception")
        return quick_parse_fallback(text)

def quick_parse_fallback(text):
    """Parse nhanh b·∫±ng regex khi AI timeout"""
    summary = text.split('\n')[0][:200] if text else 'No summary'
    
    # Detect issue type - c·∫©n th·∫≠n v·ªõi "epic link" vs "t·∫°o Epic"
    text_lower = text.lower()
    if 'bug' in text_lower or 'l·ªói' in text_lower:
        issue_type = 'Bug'
    elif 't·∫°o epic' in text_lower or 'create epic' in text_lower or text_lower.strip().startswith('epic:'):
        issue_type = 'Epic'
    elif 'improvement' in text_lower:
        issue_type = 'Improvement'
    else:
        issue_type = 'Task'  
    
    # T√¨m epic link v√† assignee b·∫±ng regex
    epic_link = None
    assignee = None
    
    # T√¨m epic link - l·∫•y to√†n b·ªô text sau "epic link ƒë·∫øn" ho·∫∑c "epic link"
    # Th·ª≠ nhi·ªÅu pattern ƒë·ªÉ t√¨m epic link
    epic_patterns = [
        r'epic\s+link\s+(?:ƒë·∫øn|to)\s+([^\n,]+?)(?:\s+v√†|\s+and|$)',  # "epic link ƒë·∫øn X"
        r'epic\s+link\s+([^\n,]+?)(?:\s+v√†|\s+and|$)',  # "epic link X"
        r'epic\s*[:\-=]\s*([^\n,]+?)(?:\s+v√†|\s+and|$)',  # "epic: X"
        r'link\s+(?:ƒë·∫øn|to)\s+epic\s+([^\n,]+?)(?:\s+v√†|\s+and|$)',  # "link ƒë·∫øn epic X"
        r'epic\s+link\s+(?:ƒë·∫øn|to)\s+([^\n]+?)(?:\n|$)',  # L·∫•y ƒë·∫øn h·∫øt d√≤ng
        r'epic\s+link\s+([^\n]+?)(?:\n|$)',  # L·∫•y ƒë·∫øn h·∫øt d√≤ng
    ]
    for pattern in epic_patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            epic_link = match.group(1).strip()
            # Lo·∫°i b·ªè c√°c t·ª´ th·ª´a ·ªü cu·ªëi
            epic_link = re.sub(r'\s+(?:v√†|and|cho|to|for).*$', '', epic_link, flags=re.IGNORECASE)
            # Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát ·ªü ƒë·∫ßu/cu·ªëi
            epic_link = epic_link.strip('.,;:!?')
            if epic_link:
                break
    
    # T√¨m assignee - th·ª≠ nhi·ªÅu pattern, ∆∞u ti√™n l·∫•y t√™n ƒë·∫ßy ƒë·ªß
    assignee_patterns = [
        r'g√°n\s+(?:task\s+n√†y\s+)?cho\s+([^\n,]+?)(?:\s+v√†|\s+and|$)',  # "g√°n cho X"
        r'g·∫Øn\s+cho\s+([^\n,]+?)(?:\s+v√†|\s+and|$)',  # "g·∫Øn cho X"
        r't·∫°o\s+task\s+g·∫Øn\s+cho\s+([^\n,]+?)(?:\s+v√†|\s+and|$)',  # "t·∫°o task g·∫Øn cho X"
        r'g√°n\s+(?:task\s+n√†y\s+)?cho\s+([^\n]+?)(?:\s+v√†|\s+and|\n|$)',  # "g√°n cho X" (l·∫•y ƒë·∫øn h·∫øt d√≤ng)
        r'assign\s+(?:to|for)?\s+([^\n,]+?)(?:\s+v√†|\s+and|$)',  # "assign to X"
        r'assignee\s*[:\-=]\s*([^\n,]+?)(?:\s+v√†|\s+and|$)',  # "assignee: X"
    ]
    for pattern in assignee_patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            assignee = match.group(1).strip()
            # Lo·∫°i b·ªè ph·∫ßn trong ngo·∫∑c ƒë∆°n (nh∆∞ "(KHN.SBU3.DEV)")
            assignee = re.sub(r'\s*\([^)]+\)', '', assignee)
            # Lo·∫°i b·ªè c√°c t·ª´ th·ª´a ·ªü cu·ªëi
            assignee = re.sub(r'\s+(?:v√†|and|cho|to|for).*$', '', assignee, flags=re.IGNORECASE)
            # Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát ·ªü ƒë·∫ßu/cu·ªëi
            assignee = assignee.strip('.,;:!?')
            if assignee and len(assignee) > 0:
                break
    
    # N·∫øu c√≥ epic_link th√¨ ph·∫£i l√† Task
    if epic_link and issue_type == 'Epic':
        issue_type = 'Task'
    
    # Clean description: lo·∫°i b·ªè ph·∫ßn instruction v·ªÅ assignee v√† epic link
    description = text
    if description:
        # Lo·∫°i b·ªè c√°c d√≤ng ch·ª©a instruction
        lines = description.split('\n')
        cleaned_lines = []
        for line in lines:
            # Lo·∫°i b·ªè d√≤ng ch·ª©a "g√°n", "assign", "epic link", "h√£y g√°n"
            if not re.search(r'(g√°n|assign|epic\s+link|h√£y\s+g√°n)', line, re.IGNORECASE):
                cleaned_lines.append(line)
        description = '\n'.join(cleaned_lines).strip()
    
    return {
        'summary': summary,
        'issuetype': issue_type,
        'description': description,
        'priority': 'Medium',
        'epic_link': epic_link,
        'assignee': assignee
    }

# ƒê√£ x√≥a c√°c h√†m duplicate: find_epic, find_epic_link_field_id, update_issue_async
# S·ª≠ d·ª•ng JiraService.find_epic(), JiraService._find_epic_link_field_id(), JiraService.update_issue() thay th·∫ø

async def process_with_timeout(message_text, background_tasks: BackgroundTasks, media_urls=None, subject=None):
    """X·ª≠ l√Ω v·ªõi timeout ƒë·ªÉ ƒë·∫£m b·∫£o response trong <5s"""
    import time
    start_time = time.time()
    
    try:
        # Wrap blocking call trong thread executor
        loop = asyncio.get_event_loop()
        
        # 1. AI ph√¢n t√≠ch (KH√îNG timeout ri√™ng, ƒë·ªÉ t·ªïng timeout qu·∫£n l√Ω)
        ai_start = time.time()
        try:
            task_info = await asyncio.wait_for(
                loop.run_in_executor(None, ask_gemini_to_parse_task, message_text),
                timeout=Config.AI_TIMEOUT  # 2.8s cho AI
            )
        except asyncio.TimeoutError:
            logger.warning("‚ö†Ô∏è AI timeout, d√πng fallback parsing")
            task_info = quick_parse_fallback(message_text)
        
        ai_time = time.time() - ai_start
        logger.info(f"‚è±Ô∏è AI processing time: {ai_time:.2f}s")
        
        if not task_info:
            task_info = quick_parse_fallback(message_text)

        # Ki·ªÉm tra Jira connection v√† JIRA_PROJECT_KEY
        if not jira_service.jira:
            logger.error("‚ùå Jira ch∆∞a ƒë∆∞·ª£c k·∫øt n·ªëi")
            return {"success": False, "message": Messages.error("Jira ch∆∞a ƒë∆∞·ª£c k·∫øt n·ªëi. Vui l√≤ng ki·ªÉm tra c·∫•u h√¨nh.")}
        
        if not JIRA_PROJECT_KEY:
            logger.error("‚ùå JIRA_PROJECT_KEY ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh")
            return {"success": False, "message": Messages.error("JIRA_PROJECT_KEY ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh.")}

        # 2. Chuy·ªÉn ƒë·ªïi dictionary th√†nh TaskInfo model
        summary = task_info.get('summary', 'No summary')
        issue_type = task_info.get('issuetype', 'Task')
        
        # Detect priority t·ª´ message
        priority = task_info.get('priority', 'Medium')
        if re.search(r'∆∞u\s*ti√™n\s*cao|high\s*priority|priority\s*high|urgent', message_text or '', re.IGNORECASE):
            priority = 'High'
        elif re.search(r'∆∞u\s*ti√™n\s*th·∫•p|low\s*priority|priority\s*low', message_text or '', re.IGNORECASE):
            priority = 'Low'

        # Try to detect due date in ISO format YYYY-MM-DD or DD/MM/YYYY
        duedate = None
        iso_match = re.search(r'(\d{4}-\d{2}-\d{2})', message_text or '')
        if iso_match:
            duedate = iso_match.group(1)
        else:
            # Look for DD/MM/YYYY or D/M/YYYY
            dm_match = re.search(r'(\b\d{1,2}/\d{1,2}/\d{4}\b)', message_text or '')
            if dm_match:
                try:
                    dt = datetime.strptime(dm_match.group(1), '%d/%m/%Y')
                    # Convert to Jira-friendly ISO date YYYY-MM-DD
                    duedate = dt.strftime('%Y-%m-%d')
                except Exception:
                    duedate = None

        # T·∫°o TaskInfo object
        task_info_obj = TaskInfo(
            summary=summary,
            description=task_info.get('description', 'No description'),
            issuetype=issue_type,
            priority=priority,
            epic_link=task_info.get('epic_link'),
            assignee=task_info.get('assignee'),
            due_date=duedate,
            media_urls=list(media_urls) if media_urls else []
        )

        # T·∫°o issue ngay l·∫≠p t·ª©c s·ª≠ d·ª•ng JiraService
        jira_start = time.time()
        try:
            new_issue = await loop.run_in_executor(
                None, 
                lambda: jira_service.create_issue(task_info_obj)
            )
        except Exception as e:
            logger.error(f"‚ùå L·ªói khi t·∫°o issue: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return {"success": False, "message": Messages.error(f"Kh√¥ng th·ªÉ t·∫°o issue: {str(e)}")}
        
        jira_time = time.time() - jira_start
        logger.info(f"‚è±Ô∏è Jira create time: {jira_time:.2f}s")
        
        issue_url = f"{JIRA_SERVER}/browse/{new_issue.key}"
        
        # 3. C·∫≠p nh·∫≠t epic link v√† assignee trong background (n·∫øu c√≥)
        # JiraService.create_issue ƒë√£ x·ª≠ l√Ω basic fields, nh∆∞ng epic_link v√† assignee
        # c·∫ßn ƒë∆∞·ª£c update sau v√¨ c√≥ th·ªÉ c·∫ßn t√¨m ki·∫øm tr√™n Jira
        if task_info_obj.epic_link or task_info_obj.assignee:
            logger.info(f"üìã S·∫Ω c·∫≠p nh·∫≠t {new_issue.key} trong background: epic={task_info_obj.epic_link}, assignee={task_info_obj.assignee}")
            # S·ª≠ d·ª•ng JiraService.update_issue thay v√¨ update_issue_async
            background_tasks.add_task(jira_service.update_issue, new_issue.key, task_info_obj)
        else:
            logger.info(f"‚ÑπÔ∏è Kh√¥ng c√≥ epic_link ho·∫∑c assignee ƒë·ªÉ c·∫≠p nh·∫≠t cho {new_issue.key}")

        # Attach media files (images/videos) if any media URLs found
        # Media URLs ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω trong JiraService.create_issue() th√¥ng qua task_info_obj.media_urls

        # N·∫øu issue l√† Epic th√¨ t·∫°o ƒë√∫ng 4 task con v·ªõi t√™n c·ªë ƒë·ªãnh v√† KH√îNG c√≥ description
        if issue_type and issue_type.lower() == 'epic':
            # ƒê·ª£i m·ªôt ch√∫t ƒë·ªÉ Jira c√≥ th·ªùi gian commit/index epic m·ªõi tr∆∞·ªõc khi t·∫°o child
            try:
                await asyncio.sleep(2)
            except Exception:
                pass
            child_names = ['FE', 'BE', 'SQA', '[Estimate] nh·ªØng c√¥ng vi·ªác ban ƒë·∫ßu c·ªßa estimate']

            # Ki·ªÉm tra parent tr√™n Jira: ch·ªâ t·∫°o child n·∫øu parent th·ª±c s·ª± c√≥ issuetype = Epic
            try:
                parent_is_epic = False
                if jira_service.jira:
                    parent_issue = jira_service.jira.issue(new_issue.key)
                    if hasattr(parent_issue.fields, 'issuetype') and parent_issue.fields.issuetype.name.lower() == 'epic':
                        parent_is_epic = True
                    else:
                        logger.warning(f"‚ö†Ô∏è Issue {new_issue.key} kh√¥ng ph·∫£i Epic tr√™n Jira (issuetype={getattr(parent_issue.fields, 'issuetype', None)})")
                else:
                    logger.warning("‚ö†Ô∏è Jira client ch∆∞a kh·ªüi t·∫°o, b·ªè qua ki·ªÉm tra issuetype cho parent epic")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ ki·ªÉm tra issuetype c·ªßa {new_issue.key}: {e}")

            if not parent_is_epic:
                logger.info(f"‚ÑπÔ∏è B·ªè qua t·∫°o child v√¨ {new_issue.key} kh√¥ng ph·∫£i Epic tr√™n Jira")
            else:
                created_children = []
                for name in child_names:
                    child_task_info = TaskInfo(
                        summary=name,
                        description='',
                        issuetype='Task',
                        epic_link=new_issue.key  # Link ƒë·∫øn epic cha
                    )
                    try:
                        child = await loop.run_in_executor(
                            None,
                            lambda: jira_service.create_issue(child_task_info)
                        )
                        logger.info(f"‚úÖ T·∫°o child issue {child.key} cho epic {new_issue.key}")
                        created_children.append(child)
                        # ƒê·∫£m b·∫£o child c√≥ epic link: n·∫øu create_issue kh√¥ng set ƒë∆∞·ª£c, update trong background
                        try:
                            parent_summary = getattr(new_issue.fields, 'summary', None) or new_issue.key
                            bg_task_info = TaskInfo(epic_link=parent_summary)
                            background_tasks.add_task(jira_service.update_issue, child.key, bg_task_info)
                            logger.info(f"‚ÑπÔ∏è ƒê√£ schedule update ƒë·ªÉ g·∫Øn epic cho {child.key} (search by name: {parent_summary})")
                        except Exception as e:
                            logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ schedule update epic cho {child.key}: {e}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫°o child {name}: {e}")
        
        total_time = time.time() - start_time
        logger.info(f"‚è±Ô∏è Total processing time: {total_time:.2f}s")
        
        return {
            "success": True,
            "message": Messages.success(issue_type, new_issue.key, issue_url, summary),
            "issue_key": new_issue.key
        }
        
    except asyncio.TimeoutError:
        elapsed = time.time() - start_time
        logger.error(f"‚ùå Timeout khi x·ª≠ l√Ω request sau {elapsed:.2f}s")
        return {"success": False, "message": Messages.error("Qu√° th·ªùi gian x·ª≠ l√Ω (>5s)")}
    except Exception as e:
        logger.error(f"‚ùå L·ªói: {e}")
        return {"success": False, "message": Messages.error(str(e))}
@app.middleware("http")
async def add_ngrok_skip_header(request: Request, call_next):
    response = await call_next(request)
    response.headers["ngrok-skip-browser-warning"] = "true"
    return response
@app.post("/webhook/teams")
async def teams_webhook(request: Request, background_tasks: BackgroundTasks):
    headers = {"ngrok-skip-browser-warning": "true"}
    body_bytes = await request.body()
    logger.info(f"üîç D·ªØ li·ªáu th√¥ nh·∫≠n ƒë∆∞·ª£c: {body_bytes.decode()}")
    try:
        data = await request.json()
        logger.info(f"üöÄ Payload nh·∫≠n t·ª´ Power Automate: {data}")
        
        # S·ª≠a c√°ch l·∫•y d·ªØ li·ªáu ƒë·ªÉ tr√°nh l·ªói 'NoneType' object has no attribute 'strip'
        raw_text = data.get("text")
        raw_text = raw_text.strip() if raw_text else ""

        if not raw_text:
            logger.warning("‚ö†Ô∏è 'text' b·ªã None ho·∫∑c r·ªóng.")
            return {
                "status": "warning",
                "jira_message": "‚ö†Ô∏è Power Automate ch∆∞a g·ª≠i ƒë∆∞·ª£c n·ªôi dung tin nh·∫Øn. H√£y ki·ªÉm tra tab Expression."
            }

        # N·∫øu Power Automate g·ª≠i m·ªôt chu·ªói JSON (nh∆∞ logs), parse ƒë·ªÉ l·∫•y Subject / PlainText / Content / Link
        subject = None
        plain_text = None
        html_content = None
        link = None

        nested = None
        try:
            nested = json.loads(raw_text)
        except Exception:
            nested = None

        if isinstance(nested, dict):
            # H·ªó tr·ª£ nhi·ªÅu bi·∫øn th·ªÉ: teamsFlowRunContext.MessagePayload ho·∫∑c MessagePayload tr·ª±c ti·∫øp
            mp = nested.get('teamsFlowRunContext', {}).get('MessagePayload') or nested.get('MessagePayload') or {}
            # Body c√≥ th·ªÉ n·∫±m trong mp['Body']
            body = mp.get('Body') or {}
            subject = mp.get('Subject') or body.get('Subject')
            plain_text = body.get('PlainText') or mp.get('PlainText')
            html_content = body.get('Content') or mp.get('Content')
            link = mp.get('LinkToMessage') or body.get('LinkToMessage')

        # N·∫øu kh√¥ng parse ƒë∆∞·ª£c nested JSON, v·∫´n d√πng raw_text as-is
        # X√¢y d·ª±ng message_text sao cho d√≤ng ƒë·∫ßu l√† subject (n·∫øu c√≥) ƒë·ªÉ ƒë·∫£m b·∫£o summary ch√≠nh x√°c
        text_for_clean = html_content or plain_text or raw_text

        # Extract media URLs from HTML or raw text (img/src, video/src, or direct links to media files)
        media_urls = set()
        try:
            # img tags
            for m in re.finditer(r'<img[^>]+src=[\'\"]([^\'\"]+)[\'\"]', raw_text or '', re.IGNORECASE):
                media_urls.add(m.group(1))
            # video tags
            for m in re.finditer(r'<video[^>]+src=[\'\"]([^\'\"]+)[\'\"]', raw_text or '', re.IGNORECASE):
                media_urls.add(m.group(1))
            # source tags inside video/audio
            for m in re.finditer(r'<source[^>]+src=[\'\"]([^\'\"]+)[\'\"]', raw_text or '', re.IGNORECASE):
                media_urls.add(m.group(1))
            # direct links to media files (jpg/png/gif/mp4/mov/webm)
            for m in re.finditer(r'(https?://\S+?\.(?:png|jpe?g|gif|mp4|mov|webm))(?:\?|\s|\"|\'|$)', raw_text or '', re.IGNORECASE):
                media_urls.add(m.group(1))
        except Exception:
            media_urls = set()

        if subject:
            message_text = f"{subject}\n\n{text_for_clean}"
        else:
            message_text = text_for_clean

        if link:
            message_text = f"{message_text}\n\nLink: {link}"

        # L√†m s·∫°ch message (lo·∫°i b·ªè tag, gh√©p assignee n·∫øu c·∫ßn)
        message_text = clean_teams_message(message_text)
        result = await process_with_timeout(message_text, background_tasks, media_urls=list(media_urls), subject=subject)
        
        return {
            "status": "success",
            "jira_message": result["message"]
        }
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói x·ª≠ l√Ω Webhook: {e}")
        return {"status": "error", "jira_message": f"‚ùå L·ªói: {str(e)}"}


@app.post("/webhook/bitbucket")
async def bitbucket_webhook(request: Request):
    body_bytes = await request.body()
    logger.info(f"üîç Bitbucket raw: {body_bytes.decode()}")
    try:
        data = await request.json()
    except Exception as e:
        logger.error(f"‚ùå JSON parse error from Bitbucket: {e}")
        return {"status": "error", "message": "Invalid JSON"}

    try:
        result = process_bitbucket_event(data)
        status = "success" if result.get("success") else "error"
        return {"status": status, "result": result}
    except Exception as e:
        logger.error(f"‚ùå L·ªói x·ª≠ l√Ω Bitbucket webhook: {e}")
        return {"status": "error", "message": str(e)}
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
    